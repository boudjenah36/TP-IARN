{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fd495f",
   "metadata": {},
   "source": [
    "# Rapport du TP7 :  Machine à Vecteur de Support (MVS)\n",
    "\n",
    "Le but de ce rapport est d'expliquer le fonctionnement des Machine à Vecteur de Support (Support Vector Machine ou SVM), leurs entrées et leurs sorties.\n",
    "\n",
    "## Definition\n",
    "\n",
    "Le but des MVS est de trouver une fonction de séparation linéaire dont le signe servira de fonction de classification : $$sign(W^{T} X + b) \\rightarrow \\{0, 1\\}$$\n",
    "\n",
    "Pour cela, nous aimerons maximizer la largeur de la marge séparatrice entre les deux classes, pour maximiser ainsi la confiance du classifieur.\n",
    "\n",
    "## Démonstration\n",
    "On distingue deux types de marge pour les svm\n",
    "### MVS à marge stricte \n",
    "\n",
    "La formule du hyperplan séparateur est : $h = W^{T} X + b$.\n",
    "\n",
    "Une solution pour ce problème est la suivante : \n",
    "\n",
    "Si $W^{T} X + b \\geq 0 \\implies \\text{X est +}$\n",
    "\n",
    "Sinon si $W^{T} X + b < 0 \\implies \\text{X est -}$\n",
    "\n",
    "Cependant, cette règle de décision : $(\\delta) W^{T} X + b = 0$ est que même $k W, k b$ sont des solutions pour l'equation. Par conséquent, en pratique la règles suivante est employée : \n",
    "\n",
    "Pour chaque X de classe + : $W^{T} X + b \\geq 1$\n",
    "\n",
    "Pour chaque X de classe - : $W^{T} X + b \\leq -1$\n",
    "\n",
    "Et on a $y_{i} =\n",
    "\\begin{cases}\n",
    "    1 & \\quad \\text{Pour X +}\\\\\n",
    "    -1 & \\quad \\text{Pour X -}\n",
    "\\end{cases}$\n",
    "\n",
    "La règle peut donc être simplifiée comme suit:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& y_{i}(W^{T} X_{i} + b) - 1 \\geq 0 \\nonumber \\\\\n",
    "& \\text{et} \\nonumber \\\\\n",
    "& y_{i}(W^{T} X_{i} + b) - 1 = 0 \\quad \\text{ pour chaque } X_{i} \\text{ sur la frontière de décision (les marges)} \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Pour que l'hyperplan obtenu soit optimal, la largeur de la frontière de séparation doit être maximale. Les vecteurs de support qui sont les points situés sur la bordure de la frontière vont nous aider pour cela.\n",
    "\n",
    "\n",
    "\n",
    "### MVS à marge souple\n",
    "\n",
    "L'approche d'optimisation précédent aboutit à une solution seulement si les points sont linéairement séparables. Pour pallier à cet inconvénient, nous introduisons dans ce qui suit les MVS à marge souple.\n",
    "\n",
    "Nous permettons la violation des marges avec l'introduction des variables ressort $\\epsilon_{i}$ (slack variables), les formules précédentes deviennent :\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\text{min } & \\quad \\frac{1}{2} W^{T} W + C \\sum_{i=1}^{n} \\epsilon_{i}  \\quad \\text{ , C est un hyperparamètre}\\\\\n",
    "    \\text{sachant que } & \\quad y_{i}(W^{T} X_{i} + b) \\geq 1 - \\epsilon_{i}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "La variable ressort permet aux $X_{i}$ de franchir le marge et de même être sur le mauvais côté. Le $C$ permet de controler le coût d'un tel compromis, si $C$ est très grand le MVS devient strict, sinon, avec un petit $C$, il sacrifie des points pour obtenir une solution simple.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc262a",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "\n",
    "Un noyau (kernel) dans SVM est une fonction mathématique utilisée pour transformer les données d'entrée d'un espace de dimension inférieure vers un espace de dimension supérieure. Il permet de capturer des relations non linéaires entre les variables d'entrée.\n",
    "\n",
    "Le rôle d'un noyau dans SVM est de calculer les similarités entre les points d'entraînement et les points de test dans l'espace transformé. Il permet ainsi de déterminer la position des points dans cet espace et de construire une frontière de décision qui sépare les différentes classes.\n",
    "\n",
    "En utilisant des noyaux appropriés, tels que le noyau gaussien, linéaire ou polynomiale, les SVM peuvent résoudre des problèmes de classification non linéaires en trouvant des frontières de décision complexes dans l'espace de caractéristiques de dimension supérieure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dca73c",
   "metadata": {},
   "source": [
    "## Noyau gaussien \n",
    "Les noyaux gaussiens sont l'un des types de noyaux utilisés dans les SVM (Support Vector Machines). Ils sont largement utilisés pour capturer des relations non linéaires entre les variables d'entrée. Le noyau gaussien transforme les données d'entrée dans un espace de caractéristiques de dimension supérieure, où la séparation linéaire est plus facile. Il utilise une fonction gaussienne pour mesurer la similarité entre les points d'entraînement et les points de test, permettant ainsi au SVM de modéliser des relations complexes entre les variables ,la formule géneral est la suivant :\n",
    "$$ \\exp(-\\gamma \\|x-x'\\|^2)$$\n",
    "Ou $\\gamma$ est un hyperparamètre\n",
    "**les paramètres de ce noyaux sont les suivants:**\n",
    "* **C:** le paramètre C dans un SVM contrôle le compromis entre la précision de classification des exemples d'entraînement et la complexité de la frontière de décision. Des valeurs plus élevées de C conduisent à un ajustement plus précis aux données d'entraînement, mais peuvent également entraîner un surajustement. Des valeurs plus faibles de C favorisent une frontière de décision plus simple et une meilleure généralisation. En ajustant la valeur de C, on peut régulariser le modèle et trouver un équilibre optimal entre l'ajustement aux données d'entraînement et la capacité de généralisation sur de nouvelles données.\n",
    "* **Gamma:** le paramètre gamma contrôle la forme de la fonction noyau gaussien. Une valeur plus petite de gamma entraîne une courbe gaussienne plus large, ce qui signifie que les exemples d'entraînement ont une influence plus étendue. À l'inverse, une valeur plus élevée de gamma donne une courbe plus étroite, ce qui signifie que les exemples d'entraînement ont une influence plus localisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a433886",
   "metadata": {},
   "source": [
    "## Noyau polynomial\n",
    "Les noyaux polynomiaux sont un autre type de noyaux utilisés dans les SVM (Support Vector Machines). Ils sont utilisés pour capturer des relations non linéaires entre les variables d'entrée. Les noyaux polynomiaux transforment les données d'entrée dans un espace de caractéristiques de dimension supérieure en appliquant des fonctions polynomiales. Cela permet au SVM de modéliser des relations plus complexes et de créer des frontières de décision non linéaires. Les noyaux polynomiaux sont particulièrement utiles lorsque les données présentent des motifs non linéaires et peuvent aider à améliorer les performances du modèle SVM.la formule géneral est la suivant :\n",
    "$$ (\\gamma \\langle x, x'\\rangle + r)^d$$\n",
    "Ou $d$ est le degré du polynorme \n",
    "**les paramètres de ce noyaux sont les suivants:**\n",
    "* **C et Gamma :** qui ont le meme role que pour les noyaux gaussiens \n",
    "* **Le degré:** le degré est un paramètre spécifique aux noyaux polynomiaux. Il détermine la complexité de la transformation polynomiale appliquée aux données d'entrée. Un degré plus élevé permet une représentation plus complexe des relations non linéaires, mais cela peut également augmenter la complexité et le temps de calcul du modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
